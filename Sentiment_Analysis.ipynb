{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1xAxrvqmLkmAyQI39FODrlC4u_vYJ00f9",
      "authorship_tag": "ABX9TyNEegpPVXrfF5/vv3Kld8GC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharwanbagaria03/Sentiment-Analysis/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stPOxylxBrTP"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"data.csv\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "ZqclxM-KBsk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "3CFuPbmxB0dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'] = data['Review_Header'].astype(str) + ': ' + data['Review_text'].astype(str)"
      ],
      "metadata": {
        "id": "OVkpiVypB3Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(columns=['Unique_ID', 'Category', 'Rating', 'Review_Header', 'Review_text'])"
      ],
      "metadata": {
        "id": "oq0NwHbqB-oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_data = data[data['Own_Rating'] == 'Positive']\n",
        "negative_neutral_data = data[data['Own_Rating'].isin(['Negative', 'Neutral'])]\n",
        "positive_sampled_data = positive_data.sample(n=10000, random_state=42)\n",
        "data = pd.concat([negative_neutral_data, positive_sampled_data])\n",
        "data = data.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "d4Lq_tgaCAqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "vnbVVz4QrTz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "vGBe_4D1Tu32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = data['review']\n",
        "sentiments = list(data['Own_Rating'])"
      ],
      "metadata": {
        "id": "vA-VOkZCTfbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean Text data"
      ],
      "metadata": {
        "id": "OWEttR8jT36Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "ps = PorterStemmer()\n",
        "CLEANR = re.compile('<.*?>')\n",
        "\n",
        "def clean(review):\n",
        "    review = re.sub(CLEANR, '', review) # remove html tags\n",
        "    review = re.sub('[^a-zA-Z ]', '', review)\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    review = [lemmatizer.lemmatize(i) for i in review]\n",
        "    return ' '.join(review)"
      ],
      "metadata": {
        "id": "yiDY0C6wT1nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = reviews.apply(clean)\n",
        "reviews[:10]"
      ],
      "metadata": {
        "id": "xe_7H_BkT85_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.get_dummies(sentiments)['Positive']"
      ],
      "metadata": {
        "id": "bqeXZVIqUAZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(list(reviews), y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "xYyxVIV0URG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Transformers"
      ],
      "metadata": {
        "id": "kIDSupiQUYe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "QhkFFq3-UW-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "l-6mVgQzUiXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(x_train,\n",
        "                            truncation=True,\n",
        "                            padding=True)\n",
        "\n",
        "val_encodings = tokenizer(x_test,\n",
        "                            truncation=True,\n",
        "                            padding=True)"
      ],
      "metadata": {
        "id": "knF70fpCUmUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to tf.data.Dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    y_train\n",
        "))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_encodings),\n",
        "    y_test\n",
        "))"
      ],
      "metadata": {
        "id": "N7U5ieICUsSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load pre-trained model"
      ],
      "metadata": {
        "id": "J5YsGgcHUxkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model\n",
        "from transformers import TFDistilBertForSequenceClassification, AutoTokenizer\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load pre-trained model and tokenizer, change num_labels to 1\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=1)\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "viwRhIGNUwRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "sn21rhZZU6SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with BinaryCrossentropy loss and from_logits=True\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "# For num_labels=1, you should use sigmoid activation and binary cross-entropy loss\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_dataset.shuffle(100).batch(16),\n",
        "          epochs=2,\n",
        "          validation_data=val_dataset.shuffle(100).batch(16))\n"
      ],
      "metadata": {
        "id": "sG6-u8H-U8eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train for more 2 epochs\n",
        "model.fit(train_dataset.shuffle(100).batch(16),\n",
        "          epochs=2,\n",
        "          validation_data=val_dataset.shuffle(100).batch(16))"
      ],
      "metadata": {
        "id": "CqfEO2EfVAXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/output\")"
      ],
      "metadata": {
        "id": "HQKiVmw7g4WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = TFDistilBertForSequenceClassification.from_pretrained(\"/content/output\")"
      ],
      "metadata": {
        "id": "xV_jiQpvgSTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(val_dataset.batch(16)).logits\n",
        "predicted_probs = tf.sigmoid(predictions)"
      ],
      "metadata": {
        "id": "ymBCNUY-ntrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the classification function\n",
        "def classify_predictions(predictions, threshold_positive=0.7, threshold_neutral=0.3):\n",
        "    predicted_probs = tf.sigmoid(predictions)\n",
        "\n",
        "    predictions_class = []\n",
        "    for prob in predicted_probs:\n",
        "        if prob >= threshold_positive:\n",
        "            predictions_class.append('Positive')\n",
        "        elif prob <= threshold_neutral:\n",
        "            predictions_class.append('Negative')\n",
        "        else:\n",
        "            predictions_class.append('Neutral')\n",
        "\n",
        "    return predictions_class"
      ],
      "metadata": {
        "id": "1tze8cTJpQH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classified_predictions = classify_predictions(predictions)\n",
        "results_df = pd.DataFrame({'Review': x_test, 'True Sentiment': y_test, 'Predicted Sentiment': classified_predictions})"
      ],
      "metadata": {
        "id": "rCOrxLEWpZNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the results to a CSV file\n",
        "results_df.to_csv('/content/predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "goGr7gfkpkv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dxHRp-d-m6Lz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}